{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG57ccQHmIBk"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSGr2bdurcr",
        "outputId": "94ff4c99-868f-4203-b594-9370545ee4b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV2 VERSION: 4.10.0\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'xgboost'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[34], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from transformers import AutoFeatureExtractor, AutoModel, AutoTokenizer, ViTFeatureExtractor, ViTModel\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import cv2\n",
        "print(f\"CV2 VERSION: {cv2.__version__}\")\n",
        "import h5py\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import random\n",
        "import os\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from cuml.svm import SVR\n",
        "import cuml\n",
        "import cudf\n",
        "import cupy as cp\n",
        "import dask_cudf\n",
        "import torch.nn as nn \n",
        "import joblib\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    # Python's built-in random module\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    # Scikit-learn\n",
        "    from sklearn.utils import check_random_state\n",
        "    check_random_state(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    cp.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(42)\n",
        "from transformers import (ViTForImageClassification, ViTImageProcessor, DeiTForImageClassification, \n",
        "                          CvtForImageClassification, AutoFeatureExtractor, CLIPModel, CLIPProcessor, \n",
        "                          ViTMAEForPreTraining, AutoImageProcessor, ViTModel)\n",
        "from accelerate import Accelerator\n",
        "print('RAPIDS version',cuml.__version__)\n",
        "torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXaktUUBzfzr",
        "outputId": "0b5dec62-b9a1-4b47-bb38-3cbc7a99b3ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/f3/6g16gz657njbldzfkk6xpjj00000gn/T/ipykernel_93247/2621145984.py:1: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_train_metadata = pd.read_csv('isic-2024-challenge/train-metadata.csv')\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'Accelerator' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df_train_metadata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misic-2024-challenge/train-metadata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m accelerator \u001b[38;5;241m=\u001b[39m \u001b[43mAccelerator\u001b[49m()  \u001b[38;5;66;03m# Automatically detects multi-GPU and mixed precision setups\u001b[39;00m\n\u001b[1;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m accelerator\u001b[38;5;241m.\u001b[39mdevice  \u001b[38;5;66;03m# Get the device from Accelerator\u001b[39;00m\n\u001b[1;32m      5\u001b[0m h5_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/isic-2024-challenge/test-image.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Accelerator' is not defined"
          ]
        }
      ],
      "source": [
        "df_train_metadata = pd.read_csv('isic-2024-challenge/train-metadata.csv')\n",
        "accelerator = Accelerator()  # Automatically detects multi-GPU and mixed precision setups\n",
        "device = accelerator.device  # Get the device from Accelerator\n",
        "\n",
        "h5_file = \"/kaggle/input/isic-2024-challenge/test-image.hdf5\"\n",
        "base_dir = \"/kaggle/input/2019-finetuned-vits/\" \n",
        "\n",
        "vit_models = [\n",
        "    (\"google/vit-base-patch16-224\", 64),\n",
        "    (\"facebook/deit-base-distilled-patch16-224\", 64),\n",
        "    (\"microsoft/cvt-13\", 64),\n",
        "    (\"facebook/dino-vitb16\", 64),\n",
        "    (\"facebook/vit-mae-base\", 32)\n",
        "]\n",
        "\n",
        "print(\"The device used:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAzoQs5N26MW"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, feature_extractor):\n",
        "        self.image_paths = image_paths\n",
        "        self.feature_extractor = feature_extractor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        # Preprocess the image using the feature extractor\n",
        "        inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
        "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}  # Remove batch dimension\n",
        "        return inputs\n",
        "    def __del__(self):\n",
        "        # Ensure the HDF5 file is closed when the dataset object is deleted\n",
        "        self.h5_file.close()\n",
        "\n",
        "def get_model_and_preprocessor(model_dir, num_labels=2, base_dir=\"/Users/jimmyhe/Desktop/KaggleCompetitions/ISISCANCER/HF_2019_finetuned/\"):\n",
        "    model_dir = model_dir.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
        "    # Define the path to the model folder (no need to access individual files inside it)\n",
        "    model_folder = os.path.join(base_dir, model_dir + '/')\n",
        "\n",
        "    # Detect if there's a custom `best_model.pth` or use the default Hugging Face model\n",
        "    model_path = os.path.join(model_folder, \"best_model.pth\")\n",
        "\n",
        "    if \"vit\" in model_dir:\n",
        "        model = ViTForImageClassification.from_pretrained(model_folder, num_labels=num_labels)\n",
        "        preprocessor = ViTImageProcessor.from_pretrained(model_folder)\n",
        "    elif \"dino\" in model_dir:\n",
        "        model = ViTModel.from_pretrained(model_folder)\n",
        "        preprocessor = ViTImageProcessor.from_pretrained(model_folder)\n",
        "    elif \"deit\" in model_dir:\n",
        "        model = DeiTForImageClassification.from_pretrained(model_folder, num_labels=num_labels)\n",
        "        preprocessor = AutoFeatureExtractor.from_pretrained(model_folder)\n",
        "    elif \"cvt\" in model_dir:\n",
        "        model = CvtForImageClassification.from_pretrained(model_folder, num_labels=num_labels)\n",
        "        preprocessor = AutoFeatureExtractor.from_pretrained(model_folder)\n",
        "    elif \"clip\" in model_dir:\n",
        "        model = CLIPModel.from_pretrained(model_folder)\n",
        "        preprocessor = CLIPProcessor.from_pretrained(model_folder)\n",
        "    elif \"mae\" in model_dir:\n",
        "        model = ViTMAEForPreTraining.from_pretrained(model_folder)\n",
        "        preprocessor = AutoImageProcessor.from_pretrained(model_folder)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {model_dir}\")\n",
        "\n",
        "    # Check if custom weights exist (best_model.pth)\n",
        "    if os.path.exists(model_path):\n",
        "        model.load_state_dict(torch.load(model_path, map_location=accelerator.device))\n",
        "    \n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    return model, preprocessor\n",
        "\n",
        "def get_image_embeddings(model_name='', batch_size=32, image_paths=None):\n",
        "    all_embeddings = []\n",
        "\n",
        "\n",
        "    model, feature_extractor = get_model_and_preprocessor(model_name)\n",
        "    dataset = ImageDataset(image_paths, feature_extractor)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "    model, dataloader = accelerator.prepare(model, dataloader)\n",
        "    model.to(accelerator.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, total=len(dataloader)):\n",
        "            pixel_values = batch[\"pixel_values\"].to(accelerator)\n",
        "            with torch.cuda.amp('cuda',enabled=True):\n",
        "                model_output = model(pixel_values=pixel_values)\n",
        "            embeddings = model_output.last_hidden_state[:, 0, :]  # CLS token\n",
        "            if 'cvt' in model_name:\n",
        "                avg_pool = nn.AdaptiveAvgPool2d((1, 1))  \n",
        "                embeddings = avg_pool(model_output.last_hidden_state).squeeze()\n",
        "            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
        "            all_embeddings.extend(embeddings.cpu().numpy())\n",
        "\n",
        "        print(f\"{model_name} has embedding shape:\", embeddings.shape)\n",
        "\n",
        "    del dataset, dataloader, model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return np.array(all_embeddings)\n",
        "\n",
        "def sanitize_filename(name):\n",
        "    # Replace '/' and '-' with '_'\n",
        "    name = name.replace('/', '_').replace('-', '_')\n",
        "    # Remove any other non-alphanumeric characters (except underscore)\n",
        "    return re.sub(r'[^\\w\\-_\\.]', '', name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naUCT_eIaWEo",
        "outputId": "7715d678-8762-4724-e727-d1bb8c4bc197"
      },
      "outputs": [],
      "source": [
        "image_paths = [f\"/content/train-image/image/{id}.jpg\" for id in df_train_metadata.isic_id]\n",
        "image_paths = image_paths[:10]\n",
        "all_train_embeds = []\n",
        "for model_name, batch_size in vit_models:\n",
        "    all_embeddings = []\n",
        "    embeddings = get_image_embeddings(model_name=model_name, batch_size=batch_size, image_paths=image_paths)\n",
        "    all_embeddings.append(embeddings)\n",
        "    all_embeddings = np.vstack(all_embeddings)\n",
        "    save_directory = \"/Users/jimmyhe/Desktop/KaggleCompetitions/ISISCANCER/HF_2019_finetuned_embeddings/\"\n",
        "    os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "    # Sanitize the model_name to ensure it's a valid filename\n",
        "    safe_model_name = sanitize_filename(model_name)\n",
        "    file_path = os.path.join(save_directory, f\"finetuned_{safe_model_name}_image_embeddings.npy\")\n",
        "    all_train_embeds.append(all_embeddings)\n",
        "    print(f\"Attempting to save to: {file_path}\")\n",
        "    print(f\"embedding shape for {model_name}:\",all_embeddings.shape)\n",
        "    try:\n",
        "        np.save(file_path, all_embeddings)\n",
        "        print(f\"Successfully saved embeddings for {model_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving embeddings for {model_name}: {str(e)}\")\n",
        "        print(f\"Current working directory: {os.getcwd()}\")\n",
        "        print(f\"Directory contents: {os.listdir(save_directory)}\")\n",
        "\n",
        "\n",
        "\n",
        "def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, min_tpr: float=0.80):\n",
        "    v_gt = abs(np.asarray(solution.values)-1)\n",
        "    v_pred = np.array([1.0 - x for x in submission.values])\n",
        "    max_fpr = abs(1-min_tpr)\n",
        "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
        "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
        "    return partial_auc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "bd3mop7tjOBZ",
        "outputId": "42e474ce-9b6a-430c-c8fb-68a9d7f1022e"
      },
      "outputs": [],
      "source": [
        "# google_vit_embeddings  = np.load(\"/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/google_vit_base_patch16_224_image_embeddings.npy\")\n",
        "# facebook_vit_embeddings = np.load(\"/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/facebook_deit_small_patch16_224_image_embeddings.npy\")\n",
        "# all_embeddings = np.concatenate((google_vit_embeddings, facebook_vit_embeddings), axis=1)\n",
        "# google_vit_embeddings.shape, facebook_vit_embeddings.shape,all_embeddings.shape\n",
        "# google_vit_embeddings_fine = np.load(\"/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/finetuned/google_finetuned_vit_base_patch16_224_image_embeddings.npy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWZ9C_kqd2I_",
        "outputId": "7a83d8e1-ac17-46b1-bd5f-696fa15c3fd7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mconcatenate(all_train_embeds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m df_train_metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      4\u001b[0m FOLDS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "X = np.concatenate(all_train_embeds, axis=1)\n",
        "y = df_train_metadata['target'].values\n",
        "\n",
        "FOLDS = 5\n",
        "skf_svr = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "svr_oof = np.zeros(len(X), dtype='float32')\n",
        "svr_fold_scores = []\n",
        "mse_fold_scores = []\n",
        "trained_models = []\n",
        "for fold, (train_index, val_index) in enumerate(skf_svr.split(X, y)):\n",
        "    print('#'*50)\n",
        "    print(f'### Fold {fold+1}')\n",
        "    print('#'*50)\n",
        "\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    print(f\"Before undersampling:\")\n",
        "    print(f\"Training set shape: {X_train.shape}, Training set distribution: {np.bincount(y_train)}\")\n",
        "    print(f\"Validation set shape: {X_val.shape}, Validation set distribution: {np.bincount(y_val)}\")\n",
        "\n",
        "    # Undersample only the training data\n",
        "    undersampler = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
        "    X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
        "    print(f\"\\nAfter undersampling:\")\n",
        "    print(f\"Training set shape: {X_train_resampled.shape}, Training set distribution: {np.bincount(y_train_resampled)}\")\n",
        "    # indices = undersampler.sample_indices_\n",
        "    # positive_train_indices = np.where(y_train_resampled == 1)[0]\n",
        "    # for i, index in enumerate(positive_train_indices):\n",
        "    #   start_index = i * 5\n",
        "    #   end_index =((i + 1) * 5) -2\n",
        "    #   new_aug_embed = augmented_pos_img_embeddings[start_index:end_index]\n",
        "    #   X_train_resampled = np.vstack((X_train_resampled, new_aug_embed))\n",
        "    #   y_train_resampled = np.append(y_train_resampled, [1]*new_aug_embed.shape[0])\n",
        "    # print(f\"\\nAfter augmentation:\")\n",
        "    # print(f\"Training set shape: {X_train_resampled.shape}, Training set distribution: {np.bincount(y_train_resampled)}\")\n",
        "\n",
        "    print(f\"Validation set shape: {X_val.shape}, Validation set distribution: {np.bincount(y_val)}\")\n",
        "\n",
        "\n",
        "    X_train_cp = cp.asarray(X_train_resampled)\n",
        "    X_val_cp = cp.asarray(X_val)\n",
        "    y_train_resampled = cp.asarray(y_train_resampled)\n",
        "\n",
        "    # Initialize and train RAPIDS SVR\n",
        "    model = SVR(\n",
        "        C=1.0,\n",
        "        epsilon=0.1,\n",
        "        kernel='rbf',\n",
        "        cache_size=4096,\n",
        "        max_iter=1000,\n",
        "        tol=1e-3,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_cp, y_train_resampled)\n",
        "\n",
        "    preds = model.predict(X_val_cp)\n",
        "    print(preds[:10])\n",
        "    preds = (preds - preds.min()) / (preds.max() - preds.min())\n",
        "\n",
        "    # Move predictions back to CPU for scoring\n",
        "    preds_cpu = cp.asnumpy(preds)\n",
        "    svr_oof[val_index] = preds_cpu\n",
        "    fold_score = comp_score(pd.DataFrame(y_val), pd.DataFrame(preds_cpu))\n",
        "    svr_fold_scores.append(fold_score)\n",
        "    mse_score = mean_squared_error(y_val, preds_cpu)\n",
        "    mse_fold_scores.append(mse_score)\n",
        "    trained_models.append(model)\n",
        "\n",
        "    print(f\"Fold {fold+1} MSE: {mse_score}\")\n",
        "\n",
        "    print(f\"\\n=> Fold score: {fold_score}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "print(f\"Average MSE: {np.mean(mse_fold_scores)}\")\n",
        "print(f\"Overall MSE: {mean_squared_error(y, svr_oof)}\")\n",
        "print('#'*50)\n",
        "overall_score = comp_score(pd.DataFrame(y), pd.DataFrame(svr_oof))\n",
        "print(f'Mean fold score = {np.mean(svr_fold_scores)}')\n",
        "print(f'Overall CV score = {overall_score}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUOpCsQcHtyz"
      },
      "outputs": [],
      "source": [
        "# Specify the folder where the models will be saved\n",
        "output_folder = '/Users/jimmyhe/Desktop/KaggleCompetitions/ISISCANCER/VisualEmbeddingFinal.ipynb/final_svr/'\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Save each model into the specified folder\n",
        "for i, model in enumerate(trained_models):\n",
        "    model_path = os.path.join(output_folder, f'svr_model_fold_{i+1}.joblib')\n",
        "    joblib.dump(model, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "def get_model_and_preprocessor(model_name,model_dir,num_labels,):\n",
        "    # Load model from the directory containing the .bin and config.json\n",
        "    model = ViTForImageClassification.from_pretrained(model_dir, num_labels=num_labels)\n",
        "    \n",
        "    # Load the preprocessor (feature extractor)\n",
        "    preprocessor = ViTImageProcessor.from_pretrained(model_name)\n",
        "\n",
        "    return model, preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "    vit_models = [\n",
        "        (\"google/vit-base-patch16-224\",64),\n",
        "        # (\"facebook/deit-base-distilled-patch16-224\", 64),\n",
        "        # # (\"microsoft/cvt-13\", 64),\n",
        "        (\"facebook/dino-vitb16\", 64),\n",
        "        (\"facebook/vit-mae-base\", 32)\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "google_vit_base_patch16_224\n",
            "google/vit-base-patch16-224 loaded succcessfully\n",
            "facebook_dino_vitb16\n",
            "facebook/dino-vitb16 loaded succcessfully\n",
            "facebook_vit_mae_base\n",
            "facebook/vit-mae-base loaded succcessfully\n"
          ]
        }
      ],
      "source": [
        "for model_name, batch_size in vit_models:\n",
        "    model_name_cleaned = model_name.replace('/','_').replace('-','_')\n",
        "    print(model_name_cleaned)\n",
        "    model_dir = os.path.join('/Users/jimmyhe/Desktop/KaggleCompetitions/ISISCANCER/HF_2019_finetuned/', model_name_cleaned)\n",
        "    model, feature_extractor = get_model_and_preprocessor(model_name, model_dir, num_labels=2)\n",
        "    print(f\"{model_name} loaded succcessfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/f3/6g16gz657njbldzfkk6xpjj00000gn/T/ipykernel_93247/435010677.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(pth_model_path, map_location=torch.device('cpu'))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import DeiTForImageClassification, AutoConfig\n",
        "\n",
        "# Load the PyTorch model from the .pth file\n",
        "pth_model_path = '/Users/jimmyhe/Desktop/KaggleCompetitions/ISISCANCER/HF_2019_finetuned/facebook_deit_base_distilled_patch16_224/best_model_facebook_deit-base-distilled-patch16-224.pth'\n",
        "state_dict = torch.load(pth_model_path, map_location=torch.device('cpu'))\n",
        "\n",
        "# Initialize the Hugging Face model with the appropriate configuration\n",
        "model_name = 'facebook/deit-base-distilled-patch16-224'\n",
        "config = AutoConfig.from_pretrained(model_name, num_labels=2)  # Set num_labels=2 for binary classification\n",
        "hf_model = DeiTForImageClassification(config)\n",
        "\n",
        "# Resize classifier to match the state_dict shape\n",
        "hf_model.classifier = torch.nn.Linear(hf_model.classifier.in_features, 2)\n",
        "\n",
        "# Load the state_dict into the Hugging Face model\n",
        "hf_model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "# Save the Hugging Face model to the Hugging Face .bin format\n",
        "save_directory = 'path_to_save_hf_model'\n",
        "hf_model.save_pretrained(save_directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
