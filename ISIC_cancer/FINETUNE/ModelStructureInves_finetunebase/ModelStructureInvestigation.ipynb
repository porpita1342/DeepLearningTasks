{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 3\n",
      "Layer 0 hidden state shape: torch.Size([1, 64, 56, 56])\n",
      "Layer 1 hidden state shape: torch.Size([1, 192, 28, 28])\n",
      "Layer 2 hidden state shape: torch.Size([1, 384, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoImageProcessor, CvtModel, CvtConfig\n",
    "from PIL import Image\n",
    "\n",
    "# Open the image from the file path\n",
    "image = Image.open(\"/Users/jimmyhe/Desktop/KaggleCompetitions/ISISCANCER/MetaDataPlusProprocessed/ExmaplerPic.png\")\n",
    "# Load a ViT model and image processor\n",
    "model = CvtModel.from_pretrained('microsoft/cvt-13', output_hidden_states=True)\n",
    "processor = AutoImageProcessor.from_pretrained('microsoft/cvt-13')\n",
    "\n",
    "# Assuming image is loaded (e.g., using PIL or another method)\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# Forward pass through the model to get the hidden states\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# The model outputs a tuple where `outputs.hidden_states` contains hidden states\n",
    "hidden_states = outputs.hidden_states\n",
    "\n",
    "# Each hidden state corresponds to the output from one layer, including the embeddings\n",
    "print(f\"Number of layers: {len(hidden_states)}\")  # Should be 13 (12 transformer layers + embedding layer)\n",
    "\n",
    "# Shape of the hidden states: [batch_size, num_tokens, hidden_size]\n",
    "# num_tokens = num_patches + 1 (because of the [CLS] token)\n",
    "for i, hidden_state in enumerate(hidden_states):\n",
    "    print(f\"Layer {i} hidden state shape: {hidden_state.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 384, 14, 14]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/cvt-13\")\n",
    "model = CvtModel.from_pretrained(\"microsoft/cvt-13\")\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "list(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "avg_pool = nn.AdaptiveAvgPool2d((1, 1)) \n",
    "cls_embedding = avg_pool(last_hidden_states).squeeze()\n",
    "\n",
    "print(cls_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13\n",
      "Layer 0 hidden state shape: torch.Size([1, 197, 768])\n",
      "Layer 1 hidden state shape: torch.Size([1, 197, 768])\n",
      "Layer 2 hidden state shape: torch.Size([1, 197, 768])\n",
      "Layer 3 hidden state shape: torch.Size([1, 197, 768])\n",
      "Layer 4 hidden state shape: torch.Size([1, 197, 768])\n",
      "Layer 5 hidden state shape: torch.Size([1, 197, 768])\n",
      "Layer 6 hidden state shape: torch.Size([1, 197, 768])\n",
      "Layer 7 hidden state shape: torch.Size([1, 197, 768])\n",
      "Layer 8 hidden state shape: torch.Size([1, 197, 768])\n",
      "Layer 9 hidden state shape: torch.Size([1, 197, 768])\n",
      "Layer 10 hidden state shape: torch.Size([1, 197, 768])\n",
      "Layer 11 hidden state shape: torch.Size([1, 197, 768])\n",
      "Layer 12 hidden state shape: torch.Size([1, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "\n",
    "# Open the image from the file path\n",
    "image = Image.open(\"/Users/jimmyhe/Desktop/KaggleCompetitions/ISISCANCER/MetaDataPlusProprocessed/ExmaplerPic.png\")\n",
    "\n",
    "# Load a ViT model and image processor\n",
    "google_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "google = AutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", output_hidden_states=True)  # Enable hidden states\n",
    "\n",
    "# Assuming image is loaded (e.g., using PIL or another method)\n",
    "inputs = google_processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# Forward pass through the model to get the hidden states\n",
    "with torch.no_grad():\n",
    "    outputs = google(**inputs)\n",
    "\n",
    "# Now the model outputs should contain hidden states since we enabled it\n",
    "hidden_states = outputs.hidden_states\n",
    "\n",
    "# Each hidden state corresponds to the output from one layer, including the embeddings\n",
    "print(f\"Number of layers: {len(hidden_states)}\")  # Should be 13 (12 transformer layers + embedding layer)\n",
    "\n",
    "# Shape of the hidden states: [batch_size, num_tokens, hidden_size]\n",
    "# num_tokens = num_patches + 1 (because of the [CLS] token)\n",
    "for i, hidden_state in enumerate(hidden_states):\n",
    "    print(f\"Layer {i} hidden state shape: {hidden_state.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutputWithCLSToken' object has no attribute 'pooler_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpooler_output\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseModelOutputWithCLSToken' object has no attribute 'pooler_output'"
     ]
    }
   ],
   "source": [
    "configuration = CvtConfig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLS token embedding shape: torch.Size([1, 768])\n",
      "Mean pooled embedding shape: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "cls_embedding = hidden_states[-1][:, 0, :]  # Shape: [batch_size, hidden_size]\n",
    "\n",
    "# Mean pooling across all patch embeddings (excluding the CLS token)\n",
    "patch_embeddings = hidden_states[-1][:, 1:, :]  # Exclude CLS token\n",
    "mean_pooled_embedding = torch.mean(patch_embeddings, dim=1)  # Shape: [batch_size, hidden_size]\n",
    "\n",
    "print(\"CLS token embedding shape:\", cls_embedding.shape)\n",
    "print(\"Mean pooled embedding shape:\", mean_pooled_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CvtForImageClassification(\n",
      "  (cvt): CvtModel(\n",
      "    (encoder): CvtEncoder(\n",
      "      (stages): ModuleList(\n",
      "        (0): CvtStage(\n",
      "          (embedding): CvtEmbeddings(\n",
      "            (convolution_embeddings): CvtConvEmbeddings(\n",
      "              (projection): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n",
      "              (normalization): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layers): Sequential(\n",
      "            (0): CvtLayer(\n",
      "              (attention): CvtAttention(\n",
      "                (attention): CvtSelfAttention(\n",
      "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (projection_query): Linear(in_features=64, out_features=64, bias=True)\n",
      "                  (projection_key): Linear(in_features=64, out_features=64, bias=True)\n",
      "                  (projection_value): Linear(in_features=64, out_features=64, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): CvtSelfOutput(\n",
      "                  (dense): Linear(in_features=64, out_features=64, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): CvtIntermediate(\n",
      "                (dense): Linear(in_features=64, out_features=256, bias=True)\n",
      "                (activation): GELU(approximate='none')\n",
      "              )\n",
      "              (output): CvtOutput(\n",
      "                (dense): Linear(in_features=256, out_features=64, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path): Identity()\n",
      "              (layernorm_before): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "              (layernorm_after): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CvtStage(\n",
      "          (embedding): CvtEmbeddings(\n",
      "            (convolution_embeddings): CvtConvEmbeddings(\n",
      "              (projection): Conv2d(64, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "              (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layers): Sequential(\n",
      "            (0): CvtLayer(\n",
      "              (attention): CvtAttention(\n",
      "                (attention): CvtSelfAttention(\n",
      "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (projection_query): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (projection_key): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (projection_value): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): CvtSelfOutput(\n",
      "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): CvtIntermediate(\n",
      "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (activation): GELU(approximate='none')\n",
      "              )\n",
      "              (output): CvtOutput(\n",
      "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path): Identity()\n",
      "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (1): CvtLayer(\n",
      "              (attention): CvtAttention(\n",
      "                (attention): CvtSelfAttention(\n",
      "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (projection_query): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (projection_key): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (projection_value): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): CvtSelfOutput(\n",
      "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): CvtIntermediate(\n",
      "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (activation): GELU(approximate='none')\n",
      "              )\n",
      "              (output): CvtOutput(\n",
      "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path): Identity()\n",
      "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CvtStage(\n",
      "          (embedding): CvtEmbeddings(\n",
      "            (convolution_embeddings): CvtConvEmbeddings(\n",
      "              (projection): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "              (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layers): Sequential(\n",
      "            (0): CvtLayer(\n",
      "              (attention): CvtAttention(\n",
      "                (attention): CvtSelfAttention(\n",
      "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): CvtSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): CvtIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (activation): GELU(approximate='none')\n",
      "              )\n",
      "              (output): CvtOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (1): CvtLayer(\n",
      "              (attention): CvtAttention(\n",
      "                (attention): CvtSelfAttention(\n",
      "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): CvtSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): CvtIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (activation): GELU(approximate='none')\n",
      "              )\n",
      "              (output): CvtOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): CvtLayer(\n",
      "              (attention): CvtAttention(\n",
      "                (attention): CvtSelfAttention(\n",
      "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): CvtSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): CvtIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (activation): GELU(approximate='none')\n",
      "              )\n",
      "              (output): CvtOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (3): CvtLayer(\n",
      "              (attention): CvtAttention(\n",
      "                (attention): CvtSelfAttention(\n",
      "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): CvtSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): CvtIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (activation): GELU(approximate='none')\n",
      "              )\n",
      "              (output): CvtOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (4): CvtLayer(\n",
      "              (attention): CvtAttention(\n",
      "                (attention): CvtSelfAttention(\n",
      "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): CvtSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): CvtIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (activation): GELU(approximate='none')\n",
      "              )\n",
      "              (output): CvtOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (5): CvtLayer(\n",
      "              (attention): CvtAttention(\n",
      "                (attention): CvtSelfAttention(\n",
      "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): CvtSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): CvtIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (activation): GELU(approximate='none')\n",
      "              )\n",
      "              (output): CvtOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (6): CvtLayer(\n",
      "              (attention): CvtAttention(\n",
      "                (attention): CvtSelfAttention(\n",
      "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): CvtSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): CvtIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (activation): GELU(approximate='none')\n",
      "              )\n",
      "              (output): CvtOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (7): CvtLayer(\n",
      "              (attention): CvtAttention(\n",
      "                (attention): CvtSelfAttention(\n",
      "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): CvtSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): CvtIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (activation): GELU(approximate='none')\n",
      "              )\n",
      "              (output): CvtOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (8): CvtLayer(\n",
      "              (attention): CvtAttention(\n",
      "                (attention): CvtSelfAttention(\n",
      "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): CvtSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): CvtIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (activation): GELU(approximate='none')\n",
      "              )\n",
      "              (output): CvtOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (9): CvtLayer(\n",
      "              (attention): CvtAttention(\n",
      "                (attention): CvtSelfAttention(\n",
      "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
      "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
      "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
      "                  )\n",
      "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): CvtSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): CvtIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (activation): GELU(approximate='none')\n",
      "              )\n",
      "              (output): CvtOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layernorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "  (classifier): Linear(in_features=384, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
