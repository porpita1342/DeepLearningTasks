{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: libauc in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (1.4.0)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from libauc) (2.4.1)\n",
      "Requirement already satisfied: torchvision in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from libauc) (0.19.1)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from libauc) (1.24.4)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from libauc) (4.66.5)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from libauc) (1.10.1)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from libauc) (2.0.3)\n",
      "Requirement already satisfied: Pillow in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from libauc) (10.4.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from libauc) (1.3.2)\n",
      "Requirement already satisfied: opencv-python in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from libauc) (4.10.0.84)\n",
      "Requirement already satisfied: torch-geometric in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from libauc) (2.5.3)\n",
      "Requirement already satisfied: ogb in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from libauc) (1.3.6)\n",
      "Requirement already satisfied: webdataset in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from libauc) (0.2.100)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from ogb->libauc) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from ogb->libauc) (2.2.2)\n",
      "Requirement already satisfied: outdated>=0.2.0 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from ogb->libauc) (0.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from pandas->libauc) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from pandas->libauc) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from pandas->libauc) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from scikit-learn->libauc) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from scikit-learn->libauc) (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from torch->libauc) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from torch->libauc) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from torch->libauc) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from torch->libauc) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from torch->libauc) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from torch->libauc) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from torch-geometric->libauc) (3.10.5)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from torch-geometric->libauc) (2.32.3)\n",
      "Requirement already satisfied: pyparsing in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from torch-geometric->libauc) (3.1.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from torch-geometric->libauc) (5.9.0)\n",
      "Requirement already satisfied: braceexpand in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from webdataset->libauc) (0.1.7)\n",
      "Requirement already satisfied: pyyaml in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from webdataset->libauc) (6.0.1)\n",
      "Requirement already satisfied: setuptools>=44 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from outdated>=0.2.0->ogb->libauc) (72.1.0)\n",
      "Requirement already satisfied: littleutils in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from outdated>=0.2.0->ogb->libauc) (0.2.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from aiohttp->torch-geometric->libauc) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from aiohttp->torch-geometric->libauc) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from aiohttp->torch-geometric->libauc) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from aiohttp->torch-geometric->libauc) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from aiohttp->torch-geometric->libauc) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from aiohttp->torch-geometric->libauc) (1.9.11)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from aiohttp->torch-geometric->libauc) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from jinja2->torch->libauc) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from requests->torch-geometric->libauc) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from requests->torch-geometric->libauc) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from requests->torch-geometric->libauc) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/ISIC2020/lib/python3.8/site-packages (from sympy->torch->libauc) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import geffnet\n",
    "from resnest.torch import resnest101\n",
    "from pretrainedmodels import se_resnext101_32x4d\n",
    "import albumentations as A \n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "#from accelerate import Accelerator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import (roc_auc_score,\n",
    "                             roc_curve,\n",
    "                             auc,\n",
    "                             accuracy_score,\n",
    "                             mean_squared_error)\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "!pip install -U libauc\n",
    "from libauc.losses import pAUC_CVaR_Loss\n",
    "from libauc.optimizers import SOPA\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from accelerate import Accelerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 3\n",
    "batch_size = 64\n",
    "total_epochs = 60\n",
    "weight_decay = 5e-4 # regularization weight decay\n",
    "lr = 1e-3  # learning rate\n",
    "eta = 1e1 # learning rate for control negative samples weights\n",
    "decay_epochs = [20, 40]\n",
    "decay_factor = 10\n",
    "\n",
    "beta = 0.1 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "class Swish(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "        sigmoid_i = sigmoid(i)\n",
    "        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n",
    "class Swish_Module(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return Swish.apply(x)\n",
    "class Seresnext_Melanoma(nn.Module):\n",
    "    def __init__(self, enet_type, out_dim, n_meta_features=0, n_meta_dim=[512, 128], pretrained=False):\n",
    "        super(Seresnext_Melanoma, self).__init__()\n",
    "        self.n_meta_features = n_meta_features\n",
    "        if pretrained:\n",
    "            self.enet = se_resnext101_32x4d(num_classes=1000, pretrained='imagenet')\n",
    "        else:\n",
    "            self.enet = se_resnext101_32x4d(num_classes=1000, pretrained=None)\n",
    "        self.enet.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(0.5) for _ in range(5)\n",
    "        ])\n",
    "        in_ch = self.enet.last_linear.in_features\n",
    "        if n_meta_features > 0:\n",
    "            self.meta = nn.Sequential(\n",
    "                nn.Linear(n_meta_features, n_meta_dim[0]),\n",
    "                nn.BatchNorm1d(n_meta_dim[0]),\n",
    "                Swish_Module(),\n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.Linear(n_meta_dim[0], n_meta_dim[1]),\n",
    "                nn.BatchNorm1d(n_meta_dim[1]),\n",
    "                Swish_Module(),\n",
    "            )\n",
    "            in_ch += n_meta_dim[1]\n",
    "        self.myfc = nn.Linear(in_ch, out_dim)\n",
    "        self.enet.last_linear = nn.Identity()\n",
    "\n",
    "    def extract(self, x):\n",
    "        x = self.enet(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, x_meta=None):\n",
    "        x = self.extract(x).squeeze(-1).squeeze(-1)\n",
    "        if self.n_meta_features > 0:\n",
    "            x_meta = self.meta(x_meta)\n",
    "            x = torch.cat((x, x_meta), dim=1)\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                out = self.myfc(dropout(x))\n",
    "            else:\n",
    "                out += self.myfc(dropout(x))\n",
    "        out /= len(self.dropouts)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class Effnet_Melanoma(nn.Module):\n",
    "    def __init__(self, enet_type, out_dim, n_meta_features=0, n_meta_dim=[512, 128], pretrained=False):\n",
    "        super(Effnet_Melanoma, self).__init__()\n",
    "        self.n_meta_features = n_meta_features\n",
    "        self.enet = geffnet.create_model(enet_type, pretrained=pretrained)\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(0.5) for _ in range(5)\n",
    "        ])\n",
    "        in_ch = self.enet.classifier.in_features\n",
    "        # if n_meta_features > 0:\n",
    "        #     self.meta = nn.Sequential(\n",
    "        #         nn.Linear(n_meta_features, n_meta_dim[0]),\n",
    "        #         nn.BatchNorm1d(n_meta_dim[0]),\n",
    "        #         Swish_Module(),\n",
    "        #         nn.Dropout(p=0.3),\n",
    "        #         nn.Linear(n_meta_dim[0], n_meta_dim[1]),\n",
    "        #         nn.BatchNorm1d(n_meta_dim[1]),\n",
    "        #         Swish_Module(),\n",
    "        #     )\n",
    "        #     in_ch += n_meta_dim[1]\n",
    "        self.myfc = nn.Linear(in_ch, out_dim)\n",
    "        self.enet.classifier = nn.Identity()\n",
    "\n",
    "    def extract(self, x):\n",
    "        x = self.enet(x)\n",
    "        return x\n",
    "                        \n",
    "    def forward(self, x, x_meta=None):\n",
    "        x = self.extract(x).squeeze(-1).squeeze(-1)\n",
    "        # if self.n_meta_features > 0:\n",
    "        #     x_meta = self.meta(x_meta)\n",
    "        #     x = torch.cat((x, x_meta), dim=1)\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                out = self.myfc(dropout(x))\n",
    "            else:\n",
    "                out += self.myfc(dropout(x))\n",
    "        out /= len(self.dropouts)\n",
    "        return out\n",
    "\n",
    "class Resnest_Melanoma(nn.Module):\n",
    "    def __init__(self, enet_type, out_dim, n_meta_features=0, n_meta_dim=[512, 128], pretrained=False):\n",
    "        super(Resnest_Melanoma, self).__init__()\n",
    "        self.n_meta_features = n_meta_features\n",
    "        self.enet = resnest101(pretrained=pretrained)\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(0.5) for _ in range(5)\n",
    "        ])\n",
    "        in_ch = self.enet.fc.in_features\n",
    "        if n_meta_features > 0:\n",
    "            self.meta = nn.Sequential(\n",
    "                nn.Linear(n_meta_features, n_meta_dim[0]),\n",
    "                nn.BatchNorm1d(n_meta_dim[0]),\n",
    "                Swish_Module(),\n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.Linear(n_meta_dim[0], n_meta_dim[1]),\n",
    "                nn.BatchNorm1d(n_meta_dim[1]),\n",
    "                Swish_Module(),\n",
    "            )\n",
    "            in_ch += n_meta_dim[1]\n",
    "        self.myfc = nn.Linear(in_ch, out_dim)\n",
    "        self.enet.fc = nn.Identity()\n",
    "\n",
    "    def extract(self, x):\n",
    "        x = self.enet(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, x_meta=None):\n",
    "        x = self.extract(x).squeeze(-1).squeeze(-1)\n",
    "        if self.n_meta_features > 0:\n",
    "            x_meta = self.meta(x_meta)\n",
    "            x = torch.cat((x, x_meta), dim=1)\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                out = self.myfc(dropout(x))\n",
    "            else:\n",
    "                out += self.myfc(dropout(x))\n",
    "        out /= len(self.dropouts)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNs = [('seresnext101',Seresnext_Melanoma,640,'Melanoma_2020_models/9c_se_x101_640_ext_15ep_best_fold0.pth'),\n",
    "        ('tf_efficientnet_b4_ns',Effnet_Melanoma,448,'Melanoma_2020_models/9c_b4ns_448_ext_15ep-newfold_best_fold0.pth'),\n",
    "        ('tf_efficientnet_b5_ns',Effnet_Melanoma,448,'Melanoma_2020_models/9c_b5ns_448_ext_15ep-newfold_best_fold0.pth'),\n",
    "        ('tf_efficientnet_b6_ns',Effnet_Melanoma,576,'Melanoma_2020_models/9c_b6ns_576_ext_15ep_oldfold_best_fold0.pth'),\n",
    "        ('tf_efficientnet_b7_ns',Effnet_Melanoma,576,'Melanoma_2020_models/9c_b7ns_1e_576_ext_15ep_oldfold_best_fold0.pth'),\n",
    "        ('resnest101',Resnest_Melanoma,640,'Melanoma_2020_models/9c_nest101_2e_640_ext_15ep_best_fold0.pth')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file,img_size, img_dir, mode='train'):\n",
    "        self.data = csv_file if isinstance(csv_file, pd.DataFrame) else pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.image_paths = self.data['image'].values\n",
    "        self.labels = self.data['target'].values\n",
    "        self.image_size = img_size\n",
    "        self.mode = mode\n",
    "        if mode == 'train':\n",
    "            self.transform = A.Compose([\n",
    "                A.Transpose(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, p=0.75),\n",
    "                A.OneOf([\n",
    "                    A.MotionBlur(blur_limit=5),\n",
    "                    A.MedianBlur(blur_limit=5),\n",
    "                    A.GaussianBlur(blur_limit=5),\n",
    "                    A.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "                ], p=0.7),\n",
    "                A.OneOf([\n",
    "                    A.OpticalDistortion(distort_limit=1.0),\n",
    "                    A.GridDistortion(num_steps=5, distort_limit=1.0),\n",
    "                    A.ElasticTransform(alpha=3),\n",
    "                ], p=0.7),\n",
    "                A.CLAHE(clip_limit=4.0, p=0.7),\n",
    "                A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
    "                A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n",
    "                A.CoarseDropout(max_holes=1, max_height=int(img_size * 0.375), max_width=int(img_size * 0.375), p=0.7),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "        self.pos_indices = np.flatnonzero(self.labels==1)\n",
    "        self.pos_index_map = {}\n",
    "        for i, idx in enumerate(self.pos_indices):\n",
    "            self.pos_index_map[idx] = i\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = {}\n",
    "        img_path = os.path.join(self.img_dir, self.image_paths[idx])\n",
    "        if not os.path.exists(img_path):\n",
    "            img_path += '.jpg'\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            idx = self.pos_index_map[idx] if idx in self.pos_indices else -1\n",
    "            image = self.transform_train(image)\n",
    "        else:\n",
    "            image = self.transform_test(image)\n",
    "        \n",
    "        inputs['pixel_values'] = F.interpolate(inputs['pixel_values'], size=(self.img_size, self.img_size), mode='bilinear', align_corners=False)\n",
    "\n",
    "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "        inputs['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return inputs, idx\n",
    "def collate_fn(batch):\n",
    "    inputs = {\n",
    "        'pixel_values': torch.stack([x[0]['pixel_values'] for x in batch]),  # Access the 'pixel_values' from the dictionary\n",
    "        'labels': torch.tensor([x[0]['labels'] for x in batch])            # Access the 'labels' from the dictionary\n",
    "    } \n",
    "    indices = torch.tensor([x[1] for x in batch])  # Extract the indices from the batch\n",
    "    return inputs, indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv('/Users/jimmyhe/Desktop/KaggleCompetitions/CNNFineTune/ISIC_2019_Training_GroundTruth.csv')\n",
    "train_metadata['target'] = train_metadata[['BCC', 'SCC', 'MEL']].eq(1.0).any(axis=1).astype(int)\n",
    "path_list = [f\"/Users/jimmyhe/Desktop/KaggleCompetitions/ISISCANCER/MetaDataPlusProprocessed/train-image/image/{id}.jpg\" for id in train_metadata.image]\n",
    "path_list = path_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_length = train_metadata[train_metadata['target']==1].shape[0]\n",
    "data_length = train_metadata.shape[0]\n",
    "import logging\n",
    "import tqdm\n",
    "log_file = 'training_log.log'\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[\n",
    "    logging.FileHandler(log_file),\n",
    "    logging.StreamHandler()\n",
    "])\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['target'] for x in batch])\n",
    "    } \n",
    "def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, min_tpr: float=0.80):\n",
    "    v_gt = abs(np.asarray(solution.values)-1)\n",
    "    v_pred = np.array([1.0 - x for x in submission.values])\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return partial_auc\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    # Wrap the dataloader with tqdm to show a progress bar\n",
    "    with torch.no_grad():\n",
    "        for inputs,_ in tqdm(dataloader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "            pixel_values = inputs['pixel_values'].to(device)\n",
    "            labels = inputs['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    roc_auc = comp_score(pd.Series(all_labels), pd.Series(all_preds))\n",
    "    logger.info(f\"pAUC Score: {roc_auc:.4f}\")\n",
    "    return roc_auc\n",
    "\n",
    "def train_model(model, model_name, train_dataloader, val_dataloader, loss_fn, scheduler, device, accelerator, num_epochs=3):\n",
    "    model.train()\n",
    "    loss_log = []\n",
    "    best_pauc = 0\n",
    "    optimizer = SOPA(model, loss_fn=loss_fn, mode='adam', lr=lr, eta=eta, weight_decay=weight_decay)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        mse_loss = nn.MSELoss()\n",
    "        ce_loss = nn.CrossEntropyLoss()\n",
    "        epoch_losses = {'epoch': epoch + 1, 'total_loss': 0, 'mse_loss': 0, 'ce_loss': 0, 'auc_loss': 0, 'pauc_loss': 0}\n",
    "        train_preds, train_labels = [], []\n",
    "        for inputs, index in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\"):\n",
    "            with accelerator.accumulate(model):\n",
    "                optimizer.zero_grad()\n",
    "                pixel_values = inputs['pixel_values'].to(device)\n",
    "                labels = inputs['labels'].to(device)\n",
    "                index = index.to(device)\n",
    "                outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "                loss = loss_fn(outputs, labels, index)\n",
    "                mse = mse_loss(outputs.logits, labels.float())\n",
    "                ce = ce_loss(outputs.logits, labels.long())\n",
    "                \n",
    "                accelerator.backward(loss)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                epoch_losses['train_loss'] += loss.item()\n",
    "                train_preds.extend(torch.sigmoid(outputs.logits[:, 1]).detach().cpu().numpy())\n",
    "                train_labels.extend(inputs['labels'].cpu().numpy())\n",
    "\n",
    "        epoch_losses['train_loss'] /= len(train_dataloader)\n",
    "        epoch_losses['train_pauc'] = comp_score(pd.Series(train_labels), pd.Series(train_preds))\n",
    "        epoch_losses['train_accuracy'] = accuracy_score(train_labels, np.round(train_preds))\n",
    "        epoch_losses['train_MSE'] = mean_squared_error(train_labels, train_preds)\n",
    "            \n",
    "        # Validation\n",
    "        val_preds, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Validation\", unit=\"batch\"):\n",
    "                batch = {k: v.to(accelerator.device) for k, v in batch.items()}  # Move batch to device\n",
    "                outputs = model(**batch)\n",
    "                loss = loss_fn(outputs.logits[:, 1], batch['labels'].float())\n",
    "                \n",
    "                epoch_losses['val_loss'] += loss.item()\n",
    "                val_preds.extend(torch.sigmoid(outputs.logits[:, 1]).cpu().numpy())\n",
    "                val_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "        epoch_losses['val_loss'] /= len(val_dataloader)\n",
    "        epoch_losses['val_pauc'] = comp_score(pd.Series(val_labels), pd.Series(val_preds))\n",
    "        epoch_losses['val_accuracy'] = accuracy_score(val_labels, np.round(val_preds))\n",
    "        epoch_losses['val_MSE'] = mean_squared_error(val_labels, val_preds)\n",
    "  \n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
    "                          f\"Train Loss: {epoch_losses['train_loss']:.4f}, \"\n",
    "                          f\"Train pAUC: {epoch_losses['train_pauc']:.4f}, \"\n",
    "                          f\"Train Accuracy: {epoch_losses['train_accuracy']:.4f}, \"\n",
    "                          f\"Train MSE: {epoch_losses['train_MSE']:.4f}, \"\n",
    "                          f\"Val Loss: {epoch_losses['val_loss']:.4f}, \"\n",
    "                          f\"Val pAUC: {epoch_losses['val_pauc']:.4f}, \"\n",
    "                          f\"Val Accuracy: {epoch_losses['val_accuracy']:.4f}, \"\n",
    "                          f\"Val MSE: {epoch_losses['val_MSE']:.4f}\")\n",
    "\n",
    "        if epoch_losses['val_pauc'] > best_pauc:\n",
    "            best_pauc = epoch_losses['val_pauc']\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            accelerator.save(unwrapped_model.state_dict(), f\"{save_dir}/best_model_{model_name.replace('/', '_')}.pth\")\n",
    "        else:\n",
    "            # Save model at each epoch\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            accelerator.save(unwrapped_model.state_dict(), f\"{save_dir}/model_epoch_{epoch + 1}_{model_name.replace('/', '_')}.pth\")\n",
    "\n",
    "        # Log losses to CSV\n",
    "        loss_log.append(epoch_losses)\n",
    "        if accelerator.is_main_process:\n",
    "            pd.DataFrame(loss_log).to_csv(f\"{save_dir}/loss_log_{model_name.replace('/', '_')}.csv\", index=False)\n",
    "\n",
    "    accelerator.print(f\"Best Validation pAUC Score: {best_pauc:.4f}\")\n",
    "    return best_pauc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Iterate through each model in CNNs\n",
    "    accelerator = Accelerator()\n",
    "    DEVICE = accelerator.device\n",
    "    logger.info(f\"DEVICE USING: {DEVICE}\")\n",
    "    for enet_type, ModelClass, img_size, model_dir in CNNs:\n",
    "        print(f\"Processing {enet_type}\")\n",
    "        batch_size=64\n",
    "        # Initialize the model\n",
    "        if ModelClass == Seresnext_Melanoma:\n",
    "            model = ModelClass(enet_type, out_dim=9)\n",
    "        elif ModelClass == Effnet_Melanoma:\n",
    "            model = ModelClass(enet_type, out_dim=9)\n",
    "        elif ModelClass == Resnest_Melanoma:\n",
    "            model = ModelClass(enet_type, out_dim=9)\n",
    "        train_dataset = ImageDataset(train_metadata, path_list, mode='train')\n",
    "        val_dataset = ImageDataset(train_metadata, path_list)\n",
    "        train_dataloader = torch.utils.data.DataLoader(train_dataset, image_size=img_size,batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(model_dir, map_location=device), strict=True)\n",
    "        except:\n",
    "            state_dict = torch.load(model_dir, map_location=device)\n",
    "            state_dict = {k[7:] if k.startswith('module.') else k: state_dict[k] for k in state_dict.keys()}\n",
    "            model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "        num_training_steps = len(train_dataloader) * num_epochs\n",
    "        num_warmup_steps = int(0.1 * num_training_steps)\n",
    "        loss_fn = pAUC_CVaR_Loss(pos_len=pos_length, beta=beta)\n",
    "\n",
    "        optimizer = SOPA(model.parameters(), loss_fn=loss_fn, lr=0.1, momentum=0.9)\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "        train_model(model, enet_type, train_dataloader, val_dataloader, loss_fn, scheduler, device, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISIC2020",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
