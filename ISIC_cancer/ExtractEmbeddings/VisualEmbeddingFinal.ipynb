{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG57ccQHmIBk"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSGr2bdurcr",
        "outputId": "94ff4c99-868f-4203-b594-9370545ee4b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV2 VERSION: 4.10.0\n",
            "RAPIDS version 24.04.00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from transformers import AutoFeatureExtractor, AutoModel, AutoTokenizer, ViTFeatureExtractor, ViTModel\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import cv2\n",
        "print(f\"CV2 VERSION: {cv2.__version__}\")\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import random\n",
        "import os\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from cuml.svm import SVR\n",
        "import cuml\n",
        "import cudf\n",
        "import cupy as cp\n",
        "import dask_cudf\n",
        "from safetensors import safe_open\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    # Python's built-in random module\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    # Scikit-learn\n",
        "    from sklearn.utils import check_random_state\n",
        "    check_random_state(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    cp.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "\n",
        "print('RAPIDS version',cuml.__version__)\n",
        "torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXaktUUBzfzr",
        "outputId": "0b5dec62-b9a1-4b47-bb38-3cbc7a99b3ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-31c5ffc1815b>:1: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_train_metadata = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/train-metadata.csv')\n"
          ]
        }
      ],
      "source": [
        "df_train_metadata = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/train-metadata.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAzoQs5N26MW"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "    (\"google/vit-base-patch16-224\", 32),\n",
        "    # (\"facebook/deit-base-distilled-patch16-224\", 32),\n",
        "    # (\"microsoft/cvt-13\", 32),\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, feature_extractor):\n",
        "        self.image_paths = image_paths\n",
        "        self.feature_extractor = feature_extractor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        # Preprocess the image using the feature extractor\n",
        "        inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
        "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}  # Remove batch dimension\n",
        "        return inputs\n",
        "\n",
        "\n",
        "def load_model_from_safetensors(model_name, safetensors_path):\n",
        "    # Load the model and manually load the safetensors weights\n",
        "    model = AutoModel.from_pretrained(model_name)\n",
        "    state_dict = {}\n",
        "\n",
        "    # Load weights using safetensors\n",
        "    with safe_open(safetensors_path, framework=\"pt\") as f:\n",
        "        for key in f.keys():\n",
        "            state_dict[key] = f.get_tensor(key)\n",
        "\n",
        "    model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def get_image_embeddings(model_name='', batch_size=32, image_paths=None, safetensors_path=None):\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    all_embeddings = []\n",
        "\n",
        "    try:\n",
        "        # Load model and feature extractor\n",
        "        if safetensors_path:\n",
        "            model = load_model_from_safetensors(model_name, safetensors_path).to(DEVICE)\n",
        "        else:\n",
        "            model = AutoModel.from_pretrained(model_name).to(DEVICE)\n",
        "\n",
        "        feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
        "        model.eval()\n",
        "\n",
        "        # Create dataset and dataloader\n",
        "        dataset = ImageDataset(image_paths, feature_extractor)\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(tqdm(dataloader, total=len(dataloader))):\n",
        "                pixel_values = batch[\"pixel_values\"].to(DEVICE)\n",
        "                with torch.amp.autocast('cuda', enabled=True):\n",
        "                        model_output = model(pixel_values=pixel_values)\n",
        "                        embeddings = model_output.last_hidden[-1][:,0,:]  # or adjust this based on your model output\n",
        "                embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "                all_embeddings.extend(embeddings.cpu().numpy())\n",
        "\n",
        "                if (i + 1) % 100 == 0:  # Clear cache every 100 batches\n",
        "                    torch.cuda.empty_cache()\n",
        "        print(f\"{model_name} has embedding shape:\", embeddings.shape)\n",
        "        print(f\"Processed {len(all_embeddings)} images for {model_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing {model_name}: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    finally:\n",
        "        # Clear memory\n",
        "        del dataset, dataloader, model\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return np.array(all_embeddings)\n",
        "\n",
        "def sanitize_filename(name):\n",
        "    # Replace '/' and '-' with '_'\n",
        "    name = name.replace('/', '_').replace('-', '_')\n",
        "    # Remove any other non-alphanumeric characters (except underscore)\n",
        "    return re.sub(r'[^\\w\\-_\\.]', '', name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naUCT_eIaWEo",
        "outputId": "7715d678-8762-4724-e727-d1bb8c4bc197"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DeiTModel were not initialized from the model checkpoint at facebook/deit-base-distilled-patch16-224 and are newly initialized: ['deit.pooler.dense.bias', 'deit.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "facebook/deit-base-distilled-patch16-224 has embedding shape: torch.Size([10, 768])\n",
            "Processed 10 images for facebook/deit-base-distilled-patch16-224\n",
            "Attempting to save to: /content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/ModelsEmbeddings/facebook_deit_base_distilled_patch16_224_image_embeddings.npy\n",
            "embedding shape for facebook/deit-base-distilled-patch16-224: (10, 768)\n",
            "Successfully saved embeddings for facebook/deit-base-distilled-patch16-224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-22-be92fc65d6e2>\", line 53, in get_image_embeddings\n",
            "    embeddings = model_with_embedding(pixel_values)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"<ipython-input-22-be92fc65d6e2>\", line 24, in forward\n",
            "    features = self.model.forward_features(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1729, in __getattr__\n",
            "    raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
            "AttributeError: 'CvtModel' object has no attribute 'forward_features'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An error occurred while processing microsoft/cvt-13: 'CvtModel' object has no attribute 'forward_features'\n",
            "Attempting to save to: /content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/ModelsEmbeddings/microsoft_cvt_13_image_embeddings.npy\n",
            "embedding shape for microsoft/cvt-13: (1, 0)\n",
            "Successfully saved embeddings for microsoft/cvt-13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vitb16 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "facebook/dino-vitb16 has embedding shape: torch.Size([10, 768])\n",
            "Processed 10 images for facebook/dino-vitb16\n",
            "Attempting to save to: /content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/ModelsEmbeddings/facebook_dino_vitb16_image_embeddings.npy\n",
            "embedding shape for facebook/dino-vitb16: (10, 768)\n",
            "Successfully saved embeddings for facebook/dino-vitb16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 14.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "facebook/vit-mae-base has embedding shape: torch.Size([10, 768])\n",
            "Processed 10 images for facebook/vit-mae-base\n",
            "Attempting to save to: /content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/ModelsEmbeddings/facebook_vit_mae_base_image_embeddings.npy\n",
            "embedding shape for facebook/vit-mae-base: (10, 768)\n",
            "Successfully saved embeddings for facebook/vit-mae-base\n"
          ]
        }
      ],
      "source": [
        "image_paths = [f\"/content/train-image/image/{id}.jpg\" for id in df_train_metadata.isic_id]\n",
        "image_paths = image_paths[:10]\n",
        "for model_name, batch_size in models:\n",
        "    all_embeddings = []\n",
        "    embeddings = get_image_embeddings(model_name=model_name, batch_size=batch_size, image_paths=image_paths)\n",
        "    all_embeddings.append(embeddings)\n",
        "    all_embeddings = np.vstack(all_embeddings)\n",
        "    save_directory = \"/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/ModelsEmbeddings\"\n",
        "    os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "    # Sanitize the model_name to ensure it's a valid filename\n",
        "    safe_model_name = sanitize_filename(model_name)\n",
        "    file_path = os.path.join(save_directory, f\"{safe_model_name}_image_embeddings.npy\")\n",
        "\n",
        "    print(f\"Attempting to save to: {file_path}\")\n",
        "    print(f\"embedding shape for {model_name}:\",all_embeddings.shape)\n",
        "    try:\n",
        "        np.save(file_path, all_embeddings)\n",
        "        print(f\"Successfully saved embeddings for {model_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving embeddings for {model_name}: {str(e)}\")\n",
        "        print(f\"Current working directory: {os.getcwd()}\")\n",
        "        print(f\"Directory contents: {os.listdir(save_directory)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "bd3mop7tjOBZ",
        "outputId": "42e474ce-9b6a-430c-c8fb-68a9d7f1022e"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/google_vit_base_patch16_224_image_embeddings.npy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c23594e01347>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgoogle_vit_embeddings\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/google_vit_base_patch16_224_image_embeddings.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfacebook_vit_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/facebook_deit_small_patch16_224_image_embeddings.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoogle_vit_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacebook_vit_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgoogle_vit_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacebook_vit_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/google_vit_base_patch16_224_image_embeddings.npy'"
          ]
        }
      ],
      "source": [
        "google_vit_embeddings  = np.load(\"/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/google_vit_base_patch16_224_image_embeddings.npy\")\n",
        "facebook_vit_embeddings = np.load(\"/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/facebook_deit_small_patch16_224_image_embeddings.npy\")\n",
        "all_embeddings = np.concatenate((google_vit_embeddings, facebook_vit_embeddings), axis=1)\n",
        "google_vit_embeddings.shape, facebook_vit_embeddings.shape,all_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6_pBeK17ycl"
      },
      "outputs": [],
      "source": [
        "google_vit_embeddings_fine = np.load(\"/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/VisualEmbeddings/finetuned/google_finetuned_vit_base_patch16_224_image_embeddings.npy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqeMYGP6bxgB"
      },
      "outputs": [],
      "source": [
        "def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, min_tpr: float=0.80):\n",
        "    v_gt = abs(np.asarray(solution.values)-1)\n",
        "    v_pred = np.array([1.0 - x for x in submission.values])\n",
        "    max_fpr = abs(1-min_tpr)\n",
        "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
        "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
        "    return partial_auc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWZ9C_kqd2I_",
        "outputId": "7a83d8e1-ac17-46b1-bd5f-696fa15c3fd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##################################################\n",
            "### Fold 1\n",
            "##################################################\n",
            "Before undersampling:\n",
            "Training set shape: (320847, 768), Training set distribution: [320532    315]\n",
            "Validation set shape: (80212, 768), Validation set distribution: [80134    78]\n",
            "\n",
            "After undersampling:\n",
            "Training set shape: (3465, 768), Training set distribution: [3150  315]\n",
            "Validation set shape: (80212, 768), Validation set distribution: [80134    78]\n",
            "[D] [23:23:26.923061] /__w/cuml/cuml/cpp/src/svm/workingset.cuh:118 Creating working set with 1024 elements\n",
            "[D] [23:23:27.002045] /__w/cuml/cuml/cpp/src/svm/smosolver.cuh:255 SMO solver finished after 11 outer iterations, total inner 4202 iterations, and diff 0.000998\n",
            "[ 0.18256041  0.02420256  0.15531597 -0.05643341  0.06001154 -0.03587881\n",
            " -0.03185198  0.20800409  0.09985235  0.04926333]\n",
            "Fold 1 MSE: 0.08422665769561974\n",
            "\n",
            "=> Fold score: 0.12072083746903421\n",
            "\n",
            "\n",
            "##################################################\n",
            "### Fold 2\n",
            "##################################################\n",
            "Before undersampling:\n",
            "Training set shape: (320847, 768), Training set distribution: [320533    314]\n",
            "Validation set shape: (80212, 768), Validation set distribution: [80133    79]\n",
            "\n",
            "After undersampling:\n",
            "Training set shape: (3454, 768), Training set distribution: [3140  314]\n",
            "Validation set shape: (80212, 768), Validation set distribution: [80133    79]\n",
            "[D] [23:23:27.927303] /__w/cuml/cuml/cpp/src/svm/workingset.cuh:118 Creating working set with 1024 elements\n",
            "[D] [23:23:27.961730] /__w/cuml/cuml/cpp/src/svm/smosolver.cuh:255 SMO solver finished after 10 outer iterations, total inner 4033 iterations, and diff 0.000996\n",
            "[ 0.09143475  0.03686652  0.00707695  0.35511735 -0.07643083  0.05207065\n",
            "  0.07784775  0.04461148 -0.05373523 -0.04112181]\n",
            "Fold 2 MSE: 0.07856619792040823\n",
            "\n",
            "=> Fold score: 0.13278290348624522\n",
            "\n",
            "\n",
            "##################################################\n",
            "### Fold 3\n",
            "##################################################\n",
            "Before undersampling:\n",
            "Training set shape: (320847, 768), Training set distribution: [320533    314]\n",
            "Validation set shape: (80212, 768), Validation set distribution: [80133    79]\n",
            "\n",
            "After undersampling:\n",
            "Training set shape: (3454, 768), Training set distribution: [3140  314]\n",
            "Validation set shape: (80212, 768), Validation set distribution: [80133    79]\n",
            "[D] [23:23:28.828811] /__w/cuml/cuml/cpp/src/svm/workingset.cuh:118 Creating working set with 1024 elements\n",
            "[D] [23:23:28.864602] /__w/cuml/cuml/cpp/src/svm/smosolver.cuh:255 SMO solver finished after 11 outer iterations, total inner 4146 iterations, and diff 0.000989\n",
            "[-0.02002797 -0.06608173 -0.1476048   0.12032858  0.0956451   0.07972446\n",
            "  0.16582528  0.32738104 -0.00488648  0.20303527]\n",
            "Fold 3 MSE: 0.0838690965275784\n",
            "\n",
            "=> Fold score: 0.13459604420309457\n",
            "\n",
            "\n",
            "##################################################\n",
            "### Fold 4\n",
            "##################################################\n",
            "Before undersampling:\n",
            "Training set shape: (320847, 768), Training set distribution: [320533    314]\n",
            "Validation set shape: (80212, 768), Validation set distribution: [80133    79]\n",
            "\n",
            "After undersampling:\n",
            "Training set shape: (3454, 768), Training set distribution: [3140  314]\n",
            "Validation set shape: (80212, 768), Validation set distribution: [80133    79]\n",
            "[D] [23:23:29.730069] /__w/cuml/cuml/cpp/src/svm/workingset.cuh:118 Creating working set with 1024 elements\n",
            "[D] [23:23:29.765124] /__w/cuml/cuml/cpp/src/svm/smosolver.cuh:255 SMO solver finished after 11 outer iterations, total inner 4029 iterations, and diff 0.000997\n",
            "[-0.05339909 -0.0342766   0.16553503  0.32546782 -0.00891334  0.02131233\n",
            " -0.00928262 -0.0622198   0.0374614   0.06439835]\n",
            "Fold 4 MSE: 0.09497279927481724\n",
            "\n",
            "=> Fold score: 0.10777692845138624\n",
            "\n",
            "\n",
            "##################################################\n",
            "### Fold 5\n",
            "##################################################\n",
            "Before undersampling:\n",
            "Training set shape: (320848, 768), Training set distribution: [320533    315]\n",
            "Validation set shape: (80211, 768), Validation set distribution: [80133    78]\n",
            "\n",
            "After undersampling:\n",
            "Training set shape: (3465, 768), Training set distribution: [3150  315]\n",
            "Validation set shape: (80211, 768), Validation set distribution: [80133    78]\n",
            "[D] [23:23:30.635339] /__w/cuml/cuml/cpp/src/svm/workingset.cuh:118 Creating working set with 1024 elements\n",
            "[D] [23:23:30.672894] /__w/cuml/cuml/cpp/src/svm/smosolver.cuh:255 SMO solver finished after 12 outer iterations, total inner 4246 iterations, and diff 0.000997\n",
            "[ 0.01181287  0.11304575  0.11379063  0.08738023 -0.09583962  0.02560145\n",
            "  0.15863657  0.08435237 -0.11478871 -0.09606344]\n",
            "Fold 5 MSE: 0.0751578840326482\n",
            "\n",
            "=> Fold score: 0.1582089327774626\n",
            "\n",
            "\n",
            "Average MSE: 0.08335852709021437\n",
            "Overall MSE: 0.08335854753768732\n",
            "##################################################\n",
            "Mean fold score = 0.13081712927744457\n",
            "Overall CV score = 0.130548333589459\n",
            "Another score = 0.6365388882184647\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X = google_vit_embeddings_fine\n",
        "y = df_train_metadata['target'].values\n",
        "\n",
        "FOLDS = 5\n",
        "skf_svr = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "svr_oof = np.zeros(len(X), dtype='float32')\n",
        "svr_fold_scores = []\n",
        "mse_fold_scores = []\n",
        "trained_models = []\n",
        "for fold, (train_index, val_index) in enumerate(skf_svr.split(X, y)):\n",
        "    print('#'*50)\n",
        "    print(f'### Fold {fold+1}')\n",
        "    print('#'*50)\n",
        "\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    print(f\"Before undersampling:\")\n",
        "    print(f\"Training set shape: {X_train.shape}, Training set distribution: {np.bincount(y_train)}\")\n",
        "    print(f\"Validation set shape: {X_val.shape}, Validation set distribution: {np.bincount(y_val)}\")\n",
        "\n",
        "    # Undersample only the training data\n",
        "    undersampler = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
        "    X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
        "    print(f\"\\nAfter undersampling:\")\n",
        "    print(f\"Training set shape: {X_train_resampled.shape}, Training set distribution: {np.bincount(y_train_resampled)}\")\n",
        "    # indices = undersampler.sample_indices_\n",
        "    # positive_train_indices = np.where(y_train_resampled == 1)[0]\n",
        "    # for i, index in enumerate(positive_train_indices):\n",
        "    #   start_index = i * 5\n",
        "    #   end_index =((i + 1) * 5) -2\n",
        "    #   new_aug_embed = augmented_pos_img_embeddings[start_index:end_index]\n",
        "    #   X_train_resampled = np.vstack((X_train_resampled, new_aug_embed))\n",
        "    #   y_train_resampled = np.append(y_train_resampled, [1]*new_aug_embed.shape[0])\n",
        "    # print(f\"\\nAfter augmentation:\")\n",
        "    # print(f\"Training set shape: {X_train_resampled.shape}, Training set distribution: {np.bincount(y_train_resampled)}\")\n",
        "\n",
        "    print(f\"Validation set shape: {X_val.shape}, Validation set distribution: {np.bincount(y_val)}\")\n",
        "\n",
        "\n",
        "    X_train_cp = cp.asarray(X_train_resampled)\n",
        "    X_val_cp = cp.asarray(X_val)\n",
        "    y_train_resampled = cp.asarray(y_train_resampled)\n",
        "\n",
        "    # Initialize and train RAPIDS SVR\n",
        "    model = SVR(\n",
        "        C=1.0,\n",
        "        epsilon=0.1,\n",
        "        kernel='rbf',\n",
        "        cache_size=4096,\n",
        "        max_iter=1000,\n",
        "        tol=1e-3,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_cp, y_train_resampled)\n",
        "\n",
        "    preds = model.predict(X_val_cp)\n",
        "    print(preds[:10])\n",
        "    preds = (preds - preds.min()) / (preds.max() - preds.min())\n",
        "\n",
        "    # Move predictions back to CPU for scoring\n",
        "    preds_cpu = cp.asnumpy(preds)\n",
        "    svr_oof[val_index] = preds_cpu\n",
        "    fold_score = comp_score(pd.DataFrame(y_val), pd.DataFrame(preds_cpu))\n",
        "    svr_fold_scores.append(fold_score)\n",
        "    mse_score = mean_squared_error(y_val, preds_cpu)\n",
        "    mse_fold_scores.append(mse_score)\n",
        "    trained_models.append(model)\n",
        "\n",
        "    print(f\"Fold {fold+1} MSE: {mse_score}\")\n",
        "\n",
        "    print(f\"\\n=> Fold score: {fold_score}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "print(f\"Average MSE: {np.mean(mse_fold_scores)}\")\n",
        "print(f\"Overall MSE: {mean_squared_error(y, svr_oof)}\")\n",
        "print('#'*50)\n",
        "overall_score = comp_score(pd.DataFrame(y), pd.DataFrame(svr_oof))\n",
        "print(f'Mean fold score = {np.mean(svr_fold_scores)}')\n",
        "print(f'Overall CV score = {overall_score}')\n",
        "for i, model in enumerate(trained_models):\n",
        "    joblib.dump(model, f'svr_model_fold_{i+1}.joblib')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUOpCsQcHtyz"
      },
      "outputs": [],
      "source": [
        "# Specify the folder where the models will be saved\n",
        "output_folder = '/content/drive/MyDrive/Colab_Notebooks/SkinCancer_ISIC/VisualEmbeddingSVR/less_num_milder_aug_saved_models'\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Save each model into the specified folder\n",
        "for i, model in enumerate(trained_models):\n",
        "    model_path = os.path.join(output_folder, f'svr_model_fold_{i+1}.joblib')\n",
        "    joblib.dump(model, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T4eMmiewYeX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
